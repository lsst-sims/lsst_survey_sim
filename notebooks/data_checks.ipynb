{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some configuration content\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Who is running the notebook? Some of us have preferences ..\n",
    "username = getpass.getuser()\n",
    "# Where is the notebook running? (RSPs are 'special')\n",
    "current_location = os.getenv(\"EXTERNAL_INSTANCE_URL\", \"\")\n",
    "\n",
    "# RUBIN_SIM_DATA_DIR at usdf\n",
    "if 'usdf' in current_location:\n",
    "    os.environ[\"RUBIN_SIM_DATA_DIR\"] = \"/sdf/data/rubin/shared/rubin_sim_data\"\n",
    "\n",
    "# TOKEN CONFIGURATION\n",
    "if current_location != \"\":\n",
    "    # You are on an rsp.\n",
    "    # You should use the default RSP values, whether summit/base/USDF.\n",
    "    tokenfile = None\n",
    "    site = None\n",
    "# If you are outside of an RSP? - just use USDF and your own USDF-RSP token\n",
    "# See https://rsp.lsst.io/guides/auth/creating-user-tokens.html\n",
    "else:\n",
    "    # Substitute the location of your own tokenfile\n",
    "    tokenfile = os.getenv(\"ACCESS_TOKEN_FILE\", \"\")\n",
    "    site = os.getenv(\"DATA_SITE\", \"\")\n",
    "    if tokenfile == \"\":\n",
    "        # A very reasonable backup.\n",
    "        tokenfile = os.path.join(os.path.expanduser(\"~\"), \".lsst/usdf_rsp\")\n",
    "        site = 'usdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import copy\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import colorcet as cc\n",
    "import skyproj\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from astropy.time import Time, TimeDelta\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "from rubin_scheduler.scheduler.utils import SchemaConverter\n",
    "from rubin_scheduler.site_models import Almanac\n",
    "from rubin_scheduler.scheduler.features import Conditions\n",
    "from rubin_scheduler.utils import ddf_locations, angular_separation, approx_ra_dec2_alt_az, Site, SURVEY_START_MJD\n",
    "\n",
    "import rubin_sim.maf as maf\n",
    "from rubin_sim.data import get_baseline\n",
    "\n",
    "from rubin_nights import connections\n",
    "import rubin_nights.lfa_data as rn_lfa\n",
    "import rubin_nights.dayobs_utils as rn_dayobs\n",
    "import rubin_nights.plot_utils as rn_plots\n",
    "import rubin_nights.augment_visits as augment_visits\n",
    "import rubin_nights.rubin_scheduler_addons as rn_sch\n",
    "import rubin_nights.rubin_sim_addons as rn_sim\n",
    "import rubin_nights.observatory_status as observatory_status\n",
    "import rubin_nights.scriptqueue as scriptqueue\n",
    "import rubin_nights.scriptqueue_formatting as scriptqueue_formatting\n",
    "import rubin_nights.targets_and_visits as targets_and_visits\n",
    "\n",
    "import importlib\n",
    "\n",
    "from lsst_survey_sim import lsst_support, simulate_lsst, plot\n",
    "\n",
    "band_colors = rn_plots.PlotStyles.band_colors\n",
    "logging.getLogger('rubin_nights').setLevel(logging.INFO)\n",
    "\n",
    "#%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up connections to data (will use consdb, exposure log and narrative log)\n",
    "endpoints = connections.get_clients(tokenfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Consdb data and add some flags for bad visits, filter changes, and calculate slew times and identify expected overheads vs. excess\n",
    "\n",
    "# We query all programs to get slewtimes and idle throughout entire night\n",
    "# But these are what will be considered \"science\"\n",
    "programs = [\"BLOCK-365\", \"BLOCK-407\", \"BLOCK-408\"]\n",
    "\n",
    "# Range of day_obs for data query\n",
    "day_obs_min = 20251026\n",
    "day_obs_max = rn_dayobs.day_obs_str_to_int(rn_dayobs.today_day_obs())\n",
    "\n",
    "refresh_visits = True\n",
    "# Just a flag to make it clear if we're skipping retrieval from the consdb.\n",
    "if refresh_visits:\n",
    "    skip_imgtypes = [\"bias\", \"flat\", \"dark\"]\n",
    "    query = ( \n",
    "        \"select *, q.* from cdb_lsstcam.visit1 left join cdb_lsstcam.visit1_quicklook as q on visit1.visit_id = q.visit_id \"\n",
    "        f\"where visit1.day_obs >= {day_obs_min} and visit1.day_obs <= {day_obs_max} and img_type != 'bias' and img_type != 'flat' and img_type != 'dark'\"\n",
    "          )\n",
    "    visits = endpoints['consdb'].query(query)\n",
    "    visits = augment_visits.augment_visits(visits, \"lsstcam\")  \n",
    "    visits.reset_index(inplace=True)\n",
    "    visits.drop(\"index\", axis=1, inplace=True)\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\") \n",
    "        visits.to_hdf('v_now.h5', key='visits')\n",
    "else:\n",
    "    visits = pd.read_hdf('v_now.h5')\n",
    "print(\"all visits:\", len(visits), \"science visits:\", len(visits.query(\"science_program in @programs\")))\n",
    "\n",
    "\n",
    "if len(visits) > 0:\n",
    "    # Flag science_program changes \n",
    "    program_change = np.where((visits.science_program[:-1].values != visits.science_program[1:].values))[0]\n",
    "    program_change = program_change + 1\n",
    "    pmask = np.zeros(len(visits))\n",
    "    pmask[0] = 1\n",
    "    pmask[program_change] = 1\n",
    "    visits[\"program_change\"] = pmask\n",
    "    \n",
    "    # Flag filter changes \n",
    "    filter_change = np.where((visits.band[:-1].values != visits.band[1:].values) \n",
    "                             & (visits.day_obs[:-1].values == visits.day_obs[1:].values))[0]\n",
    "    filter_change = filter_change + 1\n",
    "    fmask = np.zeros(len(visits))\n",
    "    fmask[filter_change] = 1\n",
    "    visits[\"filter_change\"] = fmask\n",
    "    \n",
    "    # calculate slew times and identify expected overheads\n",
    "    wait_before_slew = 1.6\n",
    "    settle = 1.5\n",
    "    max_scatter = 5\n",
    "    visits, slewing = rn_sch.add_model_slew_times(visits, endpoints['efd'], model_settle=wait_before_slew + settle, dome_crawl=False, slew_while_changing_filter=False)\n",
    "    valid_overhead = np.min([np.where(np.isnan(visits.slew_model.values), 0, visits.slew_model.values) + max_scatter, visits.visit_gap.values], axis=0)\n",
    "    visits[\"overhead\"] = valid_overhead\n",
    "    \n",
    "    # Need to remove faults for the first visit of the night or where there was a different program we didn't fetch\n",
    "    # (could skip *some* of this by fetching all visits, but might still have some missing due to flats?)\n",
    "    skipped_visits = np.concatenate([np.array([0]), np.where(visits.visit_id[:-1].values + 1 != visits.visit_id[1:].values)[0] + 1])\n",
    "    \n",
    "    fault = visits.visit_gap - valid_overhead\n",
    "    fault[skipped_visits] = np.nan\n",
    "    visits[\"fault_idle\"] = fault\n",
    "    \n",
    "    visits.loc[skipped_visits, 'model_gap'] = np.nan\n",
    "    \n",
    "    # Pull lsst-dm excluded visit list to flag bad visits\n",
    "    bad_visit_ids = augment_visits.fetch_excluded_visits(\"lsstcam\")\n",
    "    visits['bad_flag'] = np.zeros(len(visits), int)\n",
    "    idx = visits.query(\"visit_id in @bad_visit_ids\").index\n",
    "    visits.loc[idx, 'bad_flag'] = 1\n",
    "    # Also pull bad visit lists from exposure log\n",
    "    ee = endpoints['exposure_log'].query_log(rn_dayobs.day_obs_to_time(day_obs_min), rn_dayobs.day_obs_to_time(day_obs_max))\n",
    "    def make_visit_id(x):\n",
    "        return f\"{x.day_obs:d}{x.seq_num:05d}\"\n",
    "    exp_log_bad_visit_ids = ee.query(\"exposure_flag == 'junk'\").apply(make_visit_id, axis=1).values\n",
    "    idx = visits.query(\"visit_id in @exp_log_bad_visit_ids\").index\n",
    "    visits.loc[idx, 'bad_flag'] = 1\n",
    "    \n",
    "    sci = visits.query(\"science_program in @programs\")\n",
    "\n",
    "else:\n",
    "    print(\"Found no visits\")\n",
    "    print(\"The remainder of this notebook requires visits.\")\n",
    "\n",
    "## thoughts -- need to mark time associated with bad visits as fault somehow .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a simple count of visits to date, split by band/date and region. \n",
    "cv = sci.groupby([\"day_obs\", \"band\"]).agg({\"obs_start_mjd\": \"count\"}).reset_index(\"band\")\n",
    "cols = [c for c in ['u', 'g', 'r', 'i', 'z', 'y'] if c in cv.band.values]\n",
    "cv = cv.pivot(columns=\"band\").droplevel(0, axis=1)[cols]\n",
    "cv['all'] = cv.sum(axis=1)\n",
    "display(cv)\n",
    "ov = sci.groupby(\"observation_reason\").agg({\"obs_start_mjd\": \"count\", \"target_name\": \"unique\"}).rename({\"obs_start_mjd\": \"count\"}, axis=1)\n",
    "def split_regions(x):\n",
    "    regions = set()\n",
    "    for k in x.target_name:\n",
    "        regions = regions.union(set([kk.replace(' ', '') for kk in k.split(',')]))\n",
    "    regions = list(regions)\n",
    "    regions.sort()\n",
    "    return regions\n",
    "ov.target_name = ov.apply(split_regions, axis=1)\n",
    "display(HTML(ov.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q = visits\n",
    "#tv, cols, to, nv, v = targets_and_visits.targets_and_visits(Time(q.obs_start_mjd.min() - 0.1/24, format='mjd', scale='tai'), Time(q.obs_start_mjd.max() + 0.1/24, format='mjd', scale='tai'), endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate typical times required for blocks (start to finish in each night)\n",
    "# Useful for knowing that, say initial alignment (BLOCK_T539) is likely to take 40 minutes with T539 and T539_hexpods\n",
    "dd = []\n",
    "q = visits\n",
    "for ddayobs in q.day_obs.unique():\n",
    "    qq = visits.query(\"day_obs == @ddayobs\")\n",
    "    p_start = qq.query(\"program_change == 1\")\n",
    "    t = list(zip(p_start.science_program.values, np.diff(p_start.obs_start_mjd.values) * 24 * 60))\n",
    "    a = pd.DataFrame([tti[0] for tti in t], columns=['block'])\n",
    "    b = pd.DataFrame([tti[1] for tti in t], columns=['time'])\n",
    "    c = pd.DataFrame([ddayobs]*len(a), columns=['dayobs'])\n",
    "    qq = a.join(b).join(c)\n",
    "    dd.append(qq)\n",
    "\n",
    "dd = pd.concat(dd)\n",
    "dd.groupby(\"block\").agg({'time': ('mean', 'median', 'max', 'min', 'count'), 'dayobs': ('min', 'max')}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot expected slewtime vs. actual visit gap\n",
    "# Sometimes we want a subset of days ..\n",
    "dayobs = visits.day_obs.unique()\n",
    "\n",
    "q = visits.query(\"science_program in @programs and day_obs in @dayobs\")\n",
    "total_time = (q.shut_time.sum() + q.overhead.sum() + q.fault_idle.sum())/3600\n",
    "total_onsky = q.exp_time.sum()/3600\n",
    "total_req = (q.shut_time.sum() + q.overhead.sum())/3600\n",
    "total_fault_idle = q.fault_idle.sum()/3600\n",
    "dd = pd.DataFrame([total_time, total_onsky, total_req, total_fault_idle, len(q), len(q)*30/3600], index=[\"time\", \"onsky\", \"req\", \"fault_idle\", \"nvis\", 'estimate time onsky'], columns=[\"all \" + \"_\".join(programs)])\n",
    "display(dd.T)\n",
    "cols = ['visit_id', 'img_type', 'observation_reason', 'obs_start_mjd', 'band', 's_ra', 's_dec', 'sky_rotation', 'altitude', 'azimuth', 'physical_rotator_angle',\n",
    "                           'clouds', 'fwhm_eff', 'filter_change', 'slew_distance', 'slew_model', 'visit_gap', 'model_gap',] #, 'overhead', 'fault_idle']\n",
    "#display(sci.query(\"model_gap > 2 and model_gap < 10\")[cols])\n",
    "\n",
    "print(f\"Min/median/mean overheads: {q.overhead.min():.2f} {q.overhead.median():.2f} {q.overhead.mean():.2f}\")\n",
    "print(f\"Min/median/mean visit gaps: {q.visit_gap.min():.2f} {q.visit_gap.median():.2f} {q.visit_gap.mean():.2f}\")\n",
    "\n",
    "#q = visits.query(\"science_program in @programs\")\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "ax = axes[0]\n",
    "ax.plot(q.visit_gap, q.slew_model, 'k.')\n",
    "x = np.arange(0, 500, 1)\n",
    "ax.plot(x, x, alpha=0.3)\n",
    "ax.fill_betweenx(x1=x+max_scatter, x2=x, y=x, color='pink', alpha=0.2) \n",
    "ax.set_xlim(0, 30)\n",
    "ax.set_ylim(0, 30)\n",
    "ax.grid(alpha=0.4)\n",
    "ax.set_xlabel(\"Visit gap (seconds)\")\n",
    "ax.set_ylabel(\"Slew model (seconds)\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(q.visit_gap, q.slew_model, 'k.')\n",
    "x = np.arange(0, 500, 1)\n",
    "ax.plot(x, x, alpha=0.3)\n",
    "ax.fill_betweenx(x1=x+max_scatter, x2=x, y=x, color='pink', alpha=0.2) \n",
    "#ax.set_xlim(0, 30)\n",
    "#ax.set_ylim(0, 30)\n",
    "ax.grid(alpha=0.4)\n",
    "ax.set_xlabel(\"Visit gap (seconds)\")\n",
    "ax.set_ylabel(\"Slew model (seconds)\")\n",
    "\n",
    "ax = axes[2]\n",
    "ax.plot(q.slew_distance, q.model_gap, 'k.')\n",
    "ax.set_ylim(-10, 10)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlabel(\"Slew distance (deg)\")\n",
    "_ = ax.set_ylabel(\"visit_gap - slew_model (seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize effect of current slew vs. \"ideal\" slew (40% + 3s settle)\n",
    "dayobs = visits.day_obs.unique()\n",
    "#dayobs = [20251108]\n",
    "q = visits.query(\"science_program in @programs and day_obs in @dayobs\")\n",
    "# Calculate \"open shutter fraction\" without faults\n",
    "slew_eff = (q.exp_time.sum()) / (q.dark_time.sum() + q.overhead.sum())\n",
    "ideal_eff = (q.exp_time.sum()) / (q.dark_time.sum() + q.slew_model_ideal.sum())\n",
    "print(f\"Slew efficiency factor: {slew_eff: 0.2f}\")\n",
    "print(f\"Ideal model efficiency equivalent: {ideal_eff: 0.2f}\")\n",
    "print(f\"Ratio - slew / ideal {slew_eff / ideal_eff :0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get narrative time lost logs\n",
    "time_lost_logs = endpoints['narrative_log'].query_log(rn_dayobs.day_obs_to_time(visits.day_obs.min()), rn_dayobs.day_obs_to_time(visits.day_obs.max()), \n",
    "                                                     {\"min_time_lost\": \"0.00001\"})\n",
    "time_lost_logs = time_lost_logs.query(\"not component.str.contains('AuxTel')\")\n",
    "def time_to_day_obs(x):\n",
    "    return int(x.date_begin.split(\"T\")[0].replace(\"-\", \"\"))\n",
    "time_lost_logs['day_obs'] = time_lost_logs.apply(time_to_day_obs, axis=1)\n",
    "log_fault = time_lost_logs.query(\"time_lost_type == 'fault'\").groupby('day_obs').agg({'time_lost': 'sum'}).rename({\"time_lost\": \"log_fault\"}, axis=1)\n",
    "log_weather = time_lost_logs.query(\"time_lost_type == 'weather'\").groupby('day_obs').agg({'time_lost': 'sum'}).rename({\"time_lost\": \"log_weather\"}, axis=1)\n",
    "log_lost = log_fault.merge(log_weather, how=\"outer\", on=\"day_obs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate time lost from visit gaps and overheads .. \n",
    "# Estimate some versions of effective system availability (per day)\n",
    "\n",
    "\n",
    "dd = {}\n",
    "for ddayobs in visits.day_obs.unique():\n",
    "    q = visits.query(\"day_obs == @ddayobs\")\n",
    "    nvis = len(q)\n",
    "    # Estimate of all fault/idle time - expect higher idle during other surveys\n",
    "    all_fault_idle = round(q.fault_idle.sum()/60/60, 2)\n",
    "    # Estimate all fault/idle time - but only where visit_gap > 5 minutes\n",
    "    gap_fault_idle = round(q.query(\"visit_gap > 5*60\").fault_idle.sum()/60/60, 2)\n",
    "    # -12 degree night length\n",
    "    sunset, sunrise = rn_dayobs.day_obs_sunset_sunrise(int(ddayobs), sun_alt=-12)\n",
    "    # Should also get dome open/close times? \n",
    "    # Estimate time from sunset to first science, and last science to sunrise.\n",
    "    qq = q.query(\"science_program in @programs\")\n",
    "    if len(qq) == 0:\n",
    "        twi_to_start = (sunrise.mjd - sunset.mjd) * 24 - gap_fault_idle\n",
    "        end_to_twi = 0\n",
    "    else:\n",
    "        twi_to_start = (qq.obs_start_mjd.min() - sunset.mjd) * 24\n",
    "        end_to_twi = (sunrise.mjd - qq.obs_end_mjd.max()) * 24\n",
    "    night_hours = (sunrise.mjd - sunset.mjd) * 24\n",
    "    # Estimate time spent in FBS compared to time expected for these visits in FBS\n",
    "    fbs = q.query(\"science_program in @programs\")\n",
    "    time_in_fbs = (fbs.obs_end_mjd.max() - fbs.obs_start_mjd.min()) * 24 \n",
    "    time_predict_in_fbs = (fbs.dark_time.sum() + fbs.slew_model_ideal.sum()) / 60 / 60        \n",
    "    dd[ddayobs] = [ddayobs, night_hours, nvis, twi_to_start, end_to_twi,  time_in_fbs, time_predict_in_fbs,  all_fault_idle, gap_fault_idle,]\n",
    "    \n",
    "dd = pd.DataFrame(dd, index=[\"day_obs\", \"night_hours\", \"n_visits\", \n",
    "                              \"twi_to_start\", \"end_to_twi\", \n",
    "                             \"time_in_fbs\", \"time_predict_in_fbs\", \n",
    "                             \"total_fault_idle\", \"total_fault_idle_gap\" ]).T\n",
    "dd = dd.merge(log_lost, how=\"outer\", on=\"day_obs\")\n",
    "dd['day_obs'] = dd['day_obs'].astype(int)\n",
    "dd.set_index(\"day_obs\", inplace=True)\n",
    "# Set time start/end of the night to the minimum of either 1.8 hours or the actual times\n",
    "# (use the min because sometimes we don't do FBS at all)\n",
    "missing_night_ends = np.min([dd.night_hours.values - dd.twi_to_start.values - dd.end_to_twi.values, np.ones(len(dd))*1.8], axis=0)\n",
    "# Now calculate the fraction of the night which could have been available for science\n",
    "ratio_night_used = (dd.night_hours - missing_night_ends) / dd.night_hours\n",
    "# Estimate the fraction of the night available/run\n",
    "ratio = round((dd.night_hours - missing_night_ends - dd.total_fault_idle_gap) / (dd.night_hours), 2)\n",
    "ratio = np.where(ratio <= 0, 0, ratio)\n",
    "dd['ratio_all_times'] = ratio * slew_eff / ideal_eff\n",
    "dd['ratio_fbs_times'] = round(dd.time_predict_in_fbs / dd.time_in_fbs * ratio_night_used, 2)\n",
    "dd['ratio_sim_ref'] = round((dd.night_hours - 0.37) / dd.night_hours, 2)\n",
    "\n",
    "non_ratio_cols = [c for c in dd if 'ratio' not in c]\n",
    "dd.loc['total', non_ratio_cols] = dd[non_ratio_cols].sum(axis=0)\n",
    "ratio_cols = [c for c in dd if 'ratio' in c]\n",
    "dd.loc['total', ratio_cols] = dd[ratio_cols].mean(axis=0)\n",
    "display(dd)\n",
    "\n",
    "print(f\"fault+idle (hours) - total: {dd.total_fault_idle_gap.sum():.2f} mean: {np.nanmean(dd.total_fault_idle_gap):.2f}\")\n",
    "\n",
    "# make an average ratio, with a fudge factor for time lost at ends of night\n",
    "ave_ratio = np.nanmean((dd.night_hours - dd.total_fault_idle_gap - 1.8)/dd.night_hours)\n",
    "ave_sim_ratio = np.mean((dd.night_hours - 0.37)/(dd.night_hours))\n",
    "print(f\"some kind of average ratio {ave_ratio:.2f} compare to {ave_sim_ratio:.2f}\")\n",
    "print(f\"Slew performance ratio {slew_eff / ideal_eff:.2f}\")\n",
    "print(f\"System availability estimate all: {np.nanmean(dd.ratio_all_times):.2f}\")\n",
    "print(f\"System availability estimate fbs: {np.nanmean(dd.ratio_fbs_times):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of above system availabity info per night\n",
    "x = np.arange(0, len(dd))\n",
    "y = dd['ratio_fbs_times']\n",
    "plt.plot(x, y, marker='.')\n",
    "_ = plt.xticks(x, dd.index, rotation=90)\n",
    "_ = plt.ylabel(\"efficiency relative to v5.1\")\n",
    "plt.figure()\n",
    "_ = plt.hist(y, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at fwhm values between block-407 (unbiased) and block-408 (bad seeing) FBS times\n",
    "# Note that prior to 20251102, these programs were intermixed without considering purpose\n",
    "bins = np.arange(0.5, 2.8, 0.05)\n",
    "q = visits.query(\"science_program == 'BLOCK-407' and day_obs >= 20251102\")\n",
    "_ = plt.hist(q.fwhm_eff.values, bins=bins, density=True, alpha=0.4, label='407')\n",
    "q = visits.query(\"science_program == 'BLOCK-408' and day_obs >= 20251102\")\n",
    "_ = plt.hist(q.fwhm_eff.values, bins=bins, density=True, alpha=0.4, label='408')\n",
    "plt.legend()\n",
    "plt.ylabel(\"Fraction of images\")\n",
    "plt.xlabel(\"FWHM (arcseconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at alt/rotator for visits. Highlight visits where slewdistance is 1.\n",
    "# This helps identify any issues with repeat visits. \n",
    "dayobs = [visits.query(\"science_program in @programs\").day_obs.max()]\n",
    "q = visits.query(\"science_program in @programs and day_obs in @dayobs\")\n",
    "qq = q.query(\"slew_distance < 0.001\")\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(q.seq_num, q.altitude, 'r.')\n",
    "plt.plot(qq.seq_num, qq.altitude, 'o', markerfacecolor='None', markeredgecolor='b')\n",
    "plt.xlabel(\"seq_num\")\n",
    "plt.ylabel(\"Altitude (deg)\")\n",
    "plt.figure(figsize=(20,  5))\n",
    "plt.plot(q.seq_num, q.physical_rotator_angle, 'r.')\n",
    "plt.plot(qq.seq_num, qq.physical_rotator_angle, 'o', markerfacecolor='None', markeredgecolor='b')\n",
    "plt.xlabel(\"seq_num\")\n",
    "plt.ylabel(\"physical rotator angle (deg)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_baseline  = False\n",
    "if compare_baseline:\n",
    "    try:\n",
    "        opsdb = \"/Users/lynnej/opsim/fbs_5.1/baseline_v5.1.0_10yrs.db\"\n",
    "        conn = sqlite3.connect(opsdb)\n",
    "    except: \n",
    "        opsdb = get_baseline()\n",
    "        conn = sqlite3.connect(opsdb)\n",
    "    \n",
    "    b_visits = pd.read_sql(f\"select * from observations where night < 365\", conn)\n",
    "    \n",
    "    tconsdb = sci.obs_start_mjd.max() - sci.obs_start_mjd.min()\n",
    "    print(f\"comparing visits within {tconsdb} days of start\")\n",
    "    baseline_visits = b_visits.query(\"observationStartMJD - observationStartMJD.min() < @tconsdb\")\n",
    "    \n",
    "    xx = baseline_visits.groupby(\"observation_reason\").agg({'observationStartMJD': \"count\"}).rename({\"observationStartMJD\": \"baseline_v5.1.0\"}, axis=1)\n",
    "    xa = sci.groupby(\"observation_reason\").agg({'obs_start_mjd': 'count'}).rename({\"obs_start_mjd\": \"consdb\"}, axis=1)\n",
    "    print(len(sci), len(baseline_visits), 'sci/baseline', len(sci)/len(baseline_visits))\n",
    "    x = pd.concat([xa, xx], axis=1)\n",
    "    x.loc['total'] = x.sum(axis=0)\n",
    "    display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize DDF visits to date\n",
    "ddf_visits = visits.query(\"bad_flag==0 and observation_reason.str.contains('DD') or observation_reason.str.contains('ddf')\").copy()\n",
    "if len(ddf_visits) > 0:\n",
    "    print(\"n visits per band\")\n",
    "    ddf_visits.loc[:, 'observation_reason'] = ddf_visits.observation_reason.str.lower()\n",
    "    ss = ddf_visits.groupby([\"observation_reason\", \"band\"]).agg({'obs_start_mjd': 'count'})\n",
    "    ss = ss.reset_index('band').pivot(columns=[\"band\"]).droplevel(0, axis=1)\n",
    "    ss['all'] = ss.sum(axis=1)\n",
    "    order = ['u', 'g', 'r', 'i', 'z', 'y', 'all']    \n",
    "    display(ss.query(\"observation_reason.str.contains('dd')\")[[o for o in order if o in ss.columns]])\n",
    "    \n",
    "    print(\"n days per band\")\n",
    "    ss = ddf_visits.groupby([\"observation_reason\", \"band\"]).agg({'day_obs': 'nunique'})\n",
    "    ss = ss.reset_index('band').pivot(columns=[\"band\"]).droplevel(0, axis=1)\n",
    "    ss['all'] = ddf_visits.groupby(\"observation_reason\").agg({'day_obs': 'nunique'})\n",
    "    display(ss.query(\"observation_reason.str.contains('dd')\")[[o for o in order if o in ss]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some all sky plots, excluding bad visits\n",
    "run_calc = True\n",
    "if run_calc:\n",
    "    gsci = sci.query(\"bad_flag == 0\")\n",
    "    nvisits = {}\n",
    "    coadd = {}\n",
    "    m_nvis = maf.CountMetric(col='obs_start_mjd', metric_name = \"Nvisits\")\n",
    "    m_coadd = maf.Coaddm5Metric(m5_col='cat_m5')\n",
    "    s = maf.HealpixSlicer(nside=64, lon_col='s_ra', lat_col='s_dec', rot_sky_pos_col_name = 'sky_rotation')\n",
    "    for b in ['u', 'g', 'r', 'i', 'z', 'y', 'all']:\n",
    "        constraint = f\"{b}\"\n",
    "        if b == 'all':\n",
    "            opsvis = gsci.to_records()\n",
    "        else:\n",
    "            opsvis = gsci.query(\"band == @b\").to_records()\n",
    "        nvisits[b] = maf.MetricBundle(m_nvis, s, constraint)\n",
    "        coadd[b] = maf.MetricBundle(m_coadd, s, constraint)\n",
    "        g = maf.MetricBundleGroup({f'nvisits {b}': nvisits[b], f'coadd {b}': coadd[b]}, None)\n",
    "        if len(opsvis) > 0:\n",
    "            g.run_current(constraint, opsvis)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = plot.get_background(nside=64)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(16, 10),)\n",
    "axdict = {\"u\": ax[0][0], \"g\": ax[0][1], \"r\": ax[0][2],\n",
    "          \"i\": ax[1][0], \"z\": ax[1][1], \"y\": ax[1][2], \"all\": None}\n",
    "for b in [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]:\n",
    "    if nvisits[b].metric_values is not None:\n",
    "        if len(nvisits[b].metric_values.compressed()) > 1:\n",
    "            vmax = np.percentile(nvisits[b].metric_values.compressed(), 95)\n",
    "        else:\n",
    "            vmax = None\n",
    "        label_dec = False\n",
    "        if b == 'u' or b == 'i':\n",
    "            label_dec = True\n",
    "        fig = plot.make_plot(nvisits[b], background=background, proj='McBryde', vmax=vmax, ax=axdict[b], title=f\"LSSTCam band {b}\", label_dec=label_dec)\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(out_dir, f\"lsstcam_nvisits_band.png\"), bbox_inches='tight')\n",
    "\n",
    "vmax = np.percentile(nvisits['all'].metric_values.compressed(), 95)\n",
    "fig = plot.make_plot(nvisits['all'], background=background, proj='mcbryde', vmin=None, vmax=vmax, ax=None, title=f\"LSSTCam visits\")\n",
    "fig = plot.make_plot(nvisits['all'], background=background, proj='laea', vmin=None, vmax=vmax, ax=None, title=f\"LSSTCam visits\")\n",
    "#fig.savefig(os.path.join(out_dir, f\"lsstcam_nvisits.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import numpy.typing as npt\n",
    "# import healpy as hp\n",
    "# from matplotlib.figure import Figure\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import matplotlib.pyplot as plt\n",
    "# from rubin_scheduler.scheduler.utils import get_current_footprint\n",
    "# import rubin_sim.maf as maf\n",
    "\n",
    "# def hp_laea(\n",
    "#     hp_array: np.ndarray,\n",
    "#     alpha: np.ndarray | None = None,\n",
    "#     label: str | None = None,\n",
    "#     vmin: float | None = None,\n",
    "#     vmax: float | None = None,\n",
    "# ) -> Figure:\n",
    "#     hp.azeqview(hp_array, alpha=alpha, rot=(0, -90, 0), \n",
    "#                 lamb=True, reso=17.5, \n",
    "#                 min=vmin, max=vmax, \n",
    "#                 title=label, \n",
    "#                 cbar=False)\n",
    "#     hp.graticule()\n",
    "#     ax = plt.gca()\n",
    "#     im = ax.get_images()[0]\n",
    "#     if vmin is None:\n",
    "#         extend = \"max\"\n",
    "#     else:\n",
    "#         extend = \"both\"\n",
    "#     cbar = plt.colorbar(\n",
    "#         im,\n",
    "#         shrink=0.45,\n",
    "#         aspect=30,\n",
    "#         pad=0.05,\n",
    "#         orientation=\"horizontal\",\n",
    "#         extendrect=False,\n",
    "#         extend=extend,\n",
    "#     )\n",
    "#     cbar.locator = MaxNLocator(nbins=3)\n",
    "#     cbar.update_ticks()\n",
    "#     return ax.get_figure()\n",
    "\n",
    "\n",
    "# def get_background(nside: int = 32) -> npt.NDArray:\n",
    "#     fp, labels = get_current_footprint(nside=nside)\n",
    "#     bg_fp = np.where(fp[\"r\"] == 0, np.nan, fp[\"r\"])\n",
    "#     bg_fp = np.where(bg_fp > 1, 1, bg_fp)\n",
    "#     return bg_fp\n",
    "\n",
    "\n",
    "# def plot_visits(day_obs_min: int, \n",
    "#                 day_obs_max: int, \n",
    "#                 visits: pd.DataFrame, \n",
    "#                 nside: int = 32) -> Figure | None:\n",
    "    \n",
    "#     qq = visits.dropna(subset=['s_ra', 's_dec', 'sky_rotation'], axis=0).query(\"day_obs >= @day_obs_min and day_obs <= @day_obs_max\").to_records()\n",
    "#     nvisits = {}\n",
    "#     m_nvis = maf.CountMetric(col='obs_start_mjd', metric_name = \"Nvisits\")\n",
    "#     s = maf.HealpixSlicer(nside=nside, \n",
    "#                           lon_col='s_ra', \n",
    "#                           lat_col='s_dec', \n",
    "#                           rot_sky_pos_col_name = 'sky_rotation',\n",
    "#                           verbose=False)\n",
    "#     constraint = ''\n",
    "#     nvisits = maf.MetricBundle(m_nvis, s, constraint, \n",
    "#                                plot_funcs=[maf.HealpixSkyMap()],\n",
    "#                               plot_dict={\"title\": f\"Visits {day_obs_min} to {day_obs_max}\",\n",
    "#                                          \"percentile_clip\": 98, \"n_ticks\": 7, \"extend\": \"max\"})\n",
    "#     g = maf.MetricBundleGroup({f'nvisits': nvisits}, None)\n",
    "#     if len(qq) > 0:\n",
    "#         g.run_current(constraint, qq) \n",
    "#         background = get_background(nside)\n",
    "#         mval = nvisits.metric_values.filled(np.nan)\n",
    "#         alpha = np.where(np.isnan(background), 0, background)\n",
    "#         alpha = np.where(alpha> 0.5, 0.5, alpha)\n",
    "#         alpha = np.where(mval > 0, 1, alpha)\n",
    "#         vmax = np.nanpercentile(mval, 95)\n",
    "#         fig = hp_laea(mval, \n",
    "#                 alpha=alpha, \n",
    "#                 label=f\"Visits {day_obs_min} to {day_obs_max}\", \n",
    "#                 vmin=None, vmax=vmax)\n",
    "#     else:\n",
    "#         fig = None\n",
    "#     return fig\n",
    "\n",
    "# fig = plot_visits(20251026, 20251119, visits, nside=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
