{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import sys\n",
    "\n",
    "username = getpass.getuser()\n",
    "location = os.getenv(\"EXTERNAL_INSTANCE_URL\", \"\")\n",
    "\n",
    "ts_config_scheduler_root = None\n",
    "\n",
    "# SOME PATH CONFIGURATION STUFF\n",
    "if username=='neilsen' and location==\"https://usdf-rsp.slac.stanford.edu\":\n",
    "    # Modifications of the python path with\n",
    "    # sys.path do not work if the same namespace\n",
    "    # is already scanned in the PYTHONPATH.\n",
    "    # Get rid of the modules pre-loaded so the\n",
    "    # interpreter reloads lsst.blah.blah.blah\n",
    "    # after we have made our modifications\n",
    "    # to sys.path.\n",
    "    sys.modules.pop(\"lsst.ts.fbs\", None)\n",
    "    sys.modules.pop(\"lsst.ts\", None)\n",
    "    sys.modules.pop(\"lsst\", None)\n",
    "    \n",
    "    sys.path.insert(0, \"/sdf/data/rubin/shared/scheduler/packages/rubin_scheduler-3.18.1\")\n",
    "    sys.path.insert(0, \"/sdf/data/rubin/shared/scheduler/packages/SP-2167/rubin_sim\")\n",
    "    sys.path.insert(0, \"/sdf/data/rubin/user/neilsen/devel/rubin_nights\")\n",
    "    sys.path.insert(0, \"/sdf/data/rubin/user/neilsen/devel/lsst_survey_sim\")\n",
    "    sys.path.insert(0, \"/sdf/data/rubin/user/neilsen/devel/ts_fbs_utils/python\")\n",
    "\n",
    "    ts_config_scheduler_root = \"/sdf/data/rubin/user/neilsen/devel/ts_config_scheduler\"\n",
    "    do_git_stuff = False\n",
    "\n",
    "elif username=='lynnej' and location == \"\":\n",
    "    ts_config_scheduler_root = \"/Users/lynnej/lsst_repos/ts_config_scheduler\"\n",
    "    do_git_stuff = True\n",
    "\n",
    "# SOME TOKEN CONFIGURATION STUFF\n",
    "# Are you on an RSP?\n",
    "if location != \"\":\n",
    "    tokenfile = None\n",
    "    site = None\n",
    "# Or are you outside of an RSP? - just use USDF and your own USDF-RSP token\n",
    "# See https://rsp.lsst.io/guides/auth/creating-user-tokens.html\n",
    "else:\n",
    "    # Substitute the location of your own tokenfile\n",
    "    # If you prefer, 'get_client' will also get token info from an \"ACCESS_TOKEN\" environment variable\n",
    "    tokenfile = os.path.join(os.path.expanduser(\"~\"), \".lsst/usdf_rsp\")\n",
    "    site = 'usdf'\n",
    "\n",
    "# Fix for Eric's tokenfile location .. we should standardize this\n",
    "if username=='neilsen' and location==\"https://usdf-rsp.slac.stanford.edu\":\n",
    "    tokenfile = \"/home/n/neilsen/.lsst/usdf_access_token\"\n",
    "\n",
    "# For everyone who did not set ts_config_scheduler_root path\n",
    "if ts_config_scheduler_root is None:\n",
    "    # Just make a new clone for ts_config_scheduler\n",
    "    ts_config_scheduler_root = \".\"\n",
    "    do_git_stuff = True\n",
    "\n",
    "\n",
    "assert isinstance(ts_config_scheduler_root, str), \"Please set ts_config_scheduler_root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import warnings\n",
    "import copy\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import colorcet as cc\n",
    "import skyproj\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from astropy.time import Time, TimeDelta\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "from rubin_scheduler.scheduler.utils import SchemaConverter\n",
    "from rubin_scheduler.site_models import Almanac\n",
    "from rubin_scheduler.scheduler.features import Conditions\n",
    "from rubin_scheduler.utils import ddf_locations, angular_separation, approx_ra_dec2_alt_az, Site, SURVEY_START_MJD\n",
    "\n",
    "import rubin_sim.maf as maf\n",
    "from rubin_sim.data import get_baseline\n",
    "\n",
    "from rubin_nights import connections\n",
    "import rubin_nights.lfa_data as rn_lfa\n",
    "import rubin_nights.dayobs_utils as rn_dayobs\n",
    "import rubin_nights.plot_utils as rn_plots\n",
    "import rubin_nights.augment_visits as augment_visits\n",
    "import rubin_nights.rubin_scheduler_addons as rn_sch\n",
    "import rubin_nights.rubin_sim_addons as rn_sim\n",
    "import rubin_nights.observatory_status as observatory_status\n",
    "import rubin_nights.scriptqueue as scriptqueue\n",
    "import rubin_nights.scriptqueue_formatting as scriptqueue_formatting\n",
    "import rubin_nights.targets_and_visits as targets_and_visits\n",
    "\n",
    "import importlib\n",
    "\n",
    "from lsst_survey_sim import lsst_support, simulate_lsst, plot\n",
    "\n",
    "band_colors = rn_plots.PlotStyles.band_colors\n",
    "logging.getLogger('lsst_survey_sim').setLevel(logging.INFO)\n",
    "\n",
    "#%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_obs = rn_dayobs.day_obs_str_to_int(rn_dayobs.today_day_obs())\n",
    "\n",
    "survey_start = SURVEY_START_MJD\n",
    "programs = [\"BLOCK-365\", \"BLOCK-407\", \"BLOCK-408\"]\n",
    "\n",
    "sunset, sunrise = rn_dayobs.day_obs_sunset_sunrise(day_obs, sun_alt=-12)\n",
    "print(f\"DayObs {day_obs}, -12 deg sunset {sunset.iso}, -12 deg sunrise {sunrise.iso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = connections.get_clients(tokenfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_visits = True\n",
    "\n",
    "day_obs_min = 20251026\n",
    "day_obs_max = rn_dayobs.day_obs_str_to_int(rn_dayobs.today_day_obs())\n",
    "\n",
    "if refresh_visits:\n",
    "    skip_imgtypes = [\"bias\", \"flat\", \"dark\"]\n",
    "    query = ( \n",
    "        \"select *, q.* from cdb_lsstcam.visit1 left join cdb_lsstcam.visit1_quicklook as q on visit1.visit_id = q.visit_id \"\n",
    "        f\"where visit1.day_obs >= {day_obs_min} and visit1.day_obs <= {day_obs_max} and img_type != 'bias' and img_type != 'flat' and img_type != 'dark'\"\n",
    "          )\n",
    "\n",
    "    # query = ( \n",
    "    #     \"select *, q.* from cdb_lsstcam.visit1 left join cdb_lsstcam.visit1_quicklook as q on visit1.visit_id = q.visit_id \"\n",
    "    #     \"where visit1.day_obs >= 20250701 and visit1.day_obs <= 20250709 and img_type != 'bias' and img_type != 'flat' and img_type != 'dark'\"\n",
    "    #       )\n",
    "    visits = endpoints['consdb'].query(query)\n",
    "    visits = augment_visits.augment_visits(visits, \"lsstcam\")  \n",
    "    visits.reset_index(inplace=True)\n",
    "    visits.drop(\"index\", axis=1, inplace=True)\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\") \n",
    "        visits.to_hdf('v_now.h5', key='visits')\n",
    "else:\n",
    "    visits = pd.read_hdf('v_now.h5')\n",
    "print(\"all visits:\", len(visits), \"science visits:\", len(visits.query(\"science_program in @programs\")))\n",
    "\n",
    "\n",
    "# Flag program changes \n",
    "program_change = np.where((visits.science_program[:-1].values != visits.science_program[1:].values))[0]\n",
    "program_change = program_change + 1\n",
    "pmask = np.zeros(len(visits))\n",
    "pmask[0] = 1\n",
    "pmask[program_change] = 1\n",
    "visits[\"program_change\"] = pmask\n",
    "\n",
    "# Flag filter changes \n",
    "filter_change = np.where((visits.band[:-1].values != visits.band[1:].values) \n",
    "                         & (visits.day_obs[:-1].values == visits.day_obs[1:].values))[0]\n",
    "filter_change = filter_change + 1\n",
    "fmask = np.zeros(len(visits))\n",
    "fmask[filter_change] = 1\n",
    "visits[\"filter_change\"] = fmask\n",
    "\n",
    "# calculate slew times \n",
    "wait_before_slew = 1.6\n",
    "settle = 1.5\n",
    "max_scatter = 5\n",
    "visits, slewing = rn_sch.add_model_slew_times(visits, endpoints['efd'], model_settle=wait_before_slew + settle, dome_crawl=False, slew_while_changing_filter=False)\n",
    "valid_overhead = np.min([np.where(np.isnan(visits.slew_model.values), 0, visits.slew_model.values) + max_scatter, visits.visit_gap.values], axis=0)\n",
    "visits[\"overhead\"] = valid_overhead\n",
    "\n",
    "# Need to remove faults for the first visit of the night or where there was a different program we didn't fetch\n",
    "# (could skip *some* of this by fetching all visits, but might still have some missing due to flats?)\n",
    "skipped_visits = np.concatenate([np.array([0]), np.where(visits.visit_id[:-1].values + 1 != visits.visit_id[1:].values)[0] + 1])\n",
    "\n",
    "fault = visits.visit_gap - valid_overhead\n",
    "fault[skipped_visits] = np.nan\n",
    "visits[\"fault_idle\"] = fault\n",
    "\n",
    "visits.loc[skipped_visits, 'model_gap'] = np.nan\n",
    "\n",
    "bad_visit_ids = augment_visits.fetch_excluded_visits(\"lsstcam\")\n",
    "visits['bad_flag'] = np.zeros(len(visits), int)\n",
    "idx = visits.query(\"visit_id in @bad_visit_ids\").index\n",
    "visits.loc[idx, 'bad_flag'] = 1\n",
    "\n",
    "sci = visits.query(\"science_program in @programs\")\n",
    "\n",
    "## thoughts -- need to mark time associated with bad visits as fault somehow .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = sci.groupby([\"day_obs\", \"band\"]).agg({\"obs_start_mjd\": \"count\"}).reset_index(\"band\")\n",
    "cols = [c for c in ['u', 'g', 'r', 'i', 'z', 'y'] if c in cv.band.values]\n",
    "cv = cv.pivot(columns=\"band\").droplevel(0, axis=1)[cols]\n",
    "cv['all'] = cv.sum(axis=1)\n",
    "display(cv)\n",
    "ov = sci.groupby(\"observation_reason\").agg({\"obs_start_mjd\": \"count\", \"target_name\": \"unique\"}).rename({\"obs_start_mjd\": \"count\"}, axis=1)\n",
    "def split_regions(x):\n",
    "    regions = set()\n",
    "    for k in x.target_name:\n",
    "        regions = regions.union(set([kk.replace(' ', '') for kk in k.split(',')]))\n",
    "    regions = list(regions)\n",
    "    regions.sort()\n",
    "    return regions\n",
    "ov.target_name = ov.apply(split_regions, axis=1)\n",
    "display(HTML(ov.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q = visits\n",
    "#tv, cols, to, nv, v = targets_and_visits.targets_and_visits(Time(q.obs_start_mjd.min() - 0.1/24, format='mjd', scale='tai'), Time(q.obs_start_mjd.max() + 0.1/24, format='mjd', scale='tai'), endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typical times required for some blocks ..\n",
    "dd = []\n",
    "q = visits\n",
    "for ddayobs in q.day_obs.unique():\n",
    "    qq = visits.query(\"day_obs == @ddayobs\")\n",
    "    p_start = qq.query(\"program_change == 1\")\n",
    "    t = list(zip(p_start.science_program.values, np.diff(p_start.obs_start_mjd.values) * 24 * 60))\n",
    "    a = pd.DataFrame([tti[0] for tti in t], columns=['block'])\n",
    "    b = pd.DataFrame([tti[1] for tti in t], columns=['time'])\n",
    "    c = pd.DataFrame([ddayobs]*len(a), columns=['dayobs'])\n",
    "    qq = a.join(b).join(c)\n",
    "    dd.append(qq)\n",
    "\n",
    "dd = pd.concat(dd)\n",
    "dd.groupby(\"block\").agg({'time': ('mean', 'median', 'max', 'min', 'count'), 'dayobs': ('min', 'max')}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayobs = visits.day_obs.unique()\n",
    "dayobs = visits.query(\"day_obs == 20251108\").day_obs.unique()\n",
    "q = visits.query(\"science_program in @programs and day_obs in @dayobs\")\n",
    "total_time = (q.shut_time.sum() + q.overhead.sum() + q.fault_idle.sum())/3600\n",
    "total_onsky = q.exp_time.sum()/3600\n",
    "total_req = (q.shut_time.sum() + q.overhead.sum())/3600\n",
    "total_fault_idle = q.fault_idle.sum()/3600\n",
    "dd = pd.DataFrame([total_time, total_onsky, total_req, total_fault_idle, len(q), len(q)*30/3600], index=[\"time\", \"onsky\", \"req\", \"fault_idle\", \"nvis\", 'estimate time onsky'], columns=[\"all \" + \"_\".join(programs)])\n",
    "display(dd.T)\n",
    "cols = ['visit_id', 'img_type', 'observation_reason', 'obs_start_mjd', 'band', 's_ra', 's_dec', 'sky_rotation', 'altitude', 'azimuth', 'physical_rotator_angle',\n",
    "                           'clouds', 'fwhm_eff', 'filter_change', 'slew_distance', 'slew_model', 'visit_gap', 'model_gap',] #, 'overhead', 'fault_idle']\n",
    "#display(sci.query(\"model_gap > 2 and model_gap < 10\")[cols])\n",
    "\n",
    "print(f\"Min/median/mean overheads: {q.overhead.min():.2f} {q.overhead.median():.2f} {q.overhead.mean():.2f}\")\n",
    "print(f\"Min/median/mean visit gaps: {q.visit_gap.min():.2f} {q.visit_gap.median():.2f} {q.visit_gap.mean():.2f}\")\n",
    "\n",
    "#q = visits.query(\"science_program in @programs\")\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "ax = axes[0]\n",
    "ax.plot(q.visit_gap, q.slew_model, 'k.')\n",
    "x = np.arange(0, 500, 1)\n",
    "ax.plot(x, x, alpha=0.3)\n",
    "ax.fill_betweenx(x1=x+max_scatter, x2=x, y=x, color='pink', alpha=0.2) \n",
    "ax.set_xlim(0, 30)\n",
    "ax.set_ylim(0, 30)\n",
    "ax.grid(alpha=0.4)\n",
    "ax.set_xlabel(\"Visit gap (seconds)\")\n",
    "ax.set_ylabel(\"Slew model (seconds)\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(q.visit_gap, q.slew_model, 'k.')\n",
    "x = np.arange(0, 500, 1)\n",
    "ax.plot(x, x, alpha=0.3)\n",
    "ax.fill_betweenx(x1=x+max_scatter, x2=x, y=x, color='pink', alpha=0.2) \n",
    "#ax.set_xlim(0, 30)\n",
    "#ax.set_ylim(0, 30)\n",
    "ax.grid(alpha=0.4)\n",
    "ax.set_xlabel(\"Visit gap (seconds)\")\n",
    "ax.set_ylabel(\"Slew model (seconds)\")\n",
    "\n",
    "ax = axes[2]\n",
    "ax.plot(q.slew_distance, q.model_gap, 'k.')\n",
    "ax.set_ylim(-10, 10)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlabel(\"Slew distance (deg)\")\n",
    "_ = ax.set_ylabel(\"visit_gap - slew_model (seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayobs = visits.day_obs.unique()\n",
    "#dayobs = [20251108]\n",
    "q = visits.query(\"science_program in @programs and day_obs in @dayobs\")\n",
    "# Calculate \"open shutter fraction\" without faults\n",
    "slew_eff = (q.exp_time.sum()) / (q.dark_time.sum() + q.overhead.sum())\n",
    "ideal_eff = (q.exp_time.sum()) / (q.dark_time.sum() + q.slew_model_ideal.sum())\n",
    "print(f\"Slew efficiency factor: {slew_eff: 0.2f}\")\n",
    "print(f\"Ideal model efficiency equivalent: {ideal_eff: 0.2f}\")\n",
    "print(f\"Ratio - slew / ideal {slew_eff / ideal_eff :0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ticketed time lost\n",
    "time_lost_logs = endpoints['narrative_log'].query_log(rn_dayobs.day_obs_to_time(visits.day_obs.min()), rn_dayobs.day_obs_to_time(visits.day_obs.max()), \n",
    "                                                     {\"min_time_lost\": \"0.00001\"})\n",
    "time_lost_logs = time_lost_logs.query(\"not component.str.contains('AuxTel')\")\n",
    "def time_to_day_obs(x):\n",
    "    return int(x.date_begin.split(\"T\")[0].replace(\"-\", \"\"))\n",
    "time_lost_logs['day_obs'] = time_lost_logs.apply(time_to_day_obs, axis=1)\n",
    "log_fault = time_lost_logs.query(\"time_lost_type == 'fault'\").groupby('day_obs').agg({'time_lost': 'sum'}).rename({\"time_lost\": \"log_fault\"}, axis=1)\n",
    "log_weather = time_lost_logs.query(\"time_lost_type == 'weather'\").groupby('day_obs').agg({'time_lost': 'sum'}).rename({\"time_lost\": \"log_weather\"}, axis=1)\n",
    "log_lost = log_fault.merge(log_weather, how=\"outer\", on=\"day_obs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time from -12 degree twilight to first science visit, and time from last visit to -12 deg\n",
    "# and fault times (total)\n",
    "dd = {}\n",
    "for ddayobs in visits.day_obs.unique():\n",
    "    q = visits.query(\"day_obs == @ddayobs\")\n",
    "    nvis = len(q)\n",
    "    all_fault_idle = round(q.fault_idle.sum()/60/60, 2)\n",
    "    gap_fault_idle = round(q.query(\"visit_gap > 5*60\").fault_idle.sum()/60/60, 2)\n",
    "    sunset, sunrise = rn_dayobs.day_obs_sunset_sunrise(int(ddayobs), sun_alt=-12)\n",
    "    qq = q.query(\"science_program in @programs\")\n",
    "    if len(qq) == 0:\n",
    "        twi_to_start = (sunrise.mjd - sunset.mjd) * 24 - gap_fault_idle\n",
    "        end_to_twi = 0\n",
    "    else:\n",
    "        twi_to_start = (qq.obs_start_mjd.min() - sunset.mjd) * 24\n",
    "        end_to_twi = (sunrise.mjd - qq.obs_end_mjd.max()) * 24\n",
    "    night_hours = (sunrise.mjd - sunset.mjd) * 24\n",
    "    fbs = q.query(\"science_program in @programs\")\n",
    "    time_in_fbs = (fbs.obs_end_mjd.max() - fbs.obs_start_mjd.min()) * 24 \n",
    "    time_predict_in_fbs = (fbs.dark_time.sum() + fbs.slew_model_ideal.sum()) / 60 / 60        \n",
    "    dd[ddayobs] = [ddayobs, night_hours, nvis, twi_to_start, end_to_twi,  time_in_fbs, time_predict_in_fbs,  all_fault_idle, gap_fault_idle,]\n",
    "dd = pd.DataFrame(dd, index=[\"day_obs\", \"night_hours\", \"n_visits\", \n",
    "                              \"twi_to_start\", \"end_to_twi\", \n",
    "                             \"time_in_fbs\", \"time_predict_in_fbs\", \n",
    "                             \"total_fault_idle\", \"total_fault_idle_gap\" ]).T\n",
    "dd = dd.merge(ticketed, how=\"outer\", on=\"day_obs\")\n",
    "dd['day_obs'] = dd['day_obs'].astype(int)\n",
    "dd.set_index(\"day_obs\", inplace=True)\n",
    "missing_night_ends = np.min([dd.night_hours.values - dd.twi_to_start.values - dd.end_to_twi.values, np.ones(len(dd))*1.8], axis=0)\n",
    "ratio_night_used = (dd.night_hours - missing_night_ends) / dd.night_hours\n",
    "ratio = round((dd.night_hours - missing_night_ends - dd.total_fault_idle_gap) / (dd.night_hours), 2)\n",
    "ratio = np.where(ratio <= 0, 0, ratio)\n",
    "dd['ratio_all_times'] = ratio * slew_eff / ideal_eff\n",
    "dd['ratio_fbs_times'] = round(dd.time_predict_in_fbs / dd.time_in_fbs * ratio_night_used, 2)\n",
    "dd['ratio_sim_ref'] = round((dd.night_hours - 0.37) / dd.night_hours, 2)\n",
    "\n",
    "non_ratio_cols = [c for c in dd if 'ratio' not in c]\n",
    "dd.loc['total', non_ratio_cols] = dd[non_ratio_cols].sum(axis=0)\n",
    "ratio_cols = [c for c in dd if 'ratio' in c]\n",
    "dd.loc['total', ratio_cols] = dd[ratio_cols].mean(axis=0)\n",
    "display(dd)\n",
    "\n",
    "print(f\"fault+idle (hours) - total: {dd.total_fault_idle_gap.sum():.2f} mean: {np.nanmean(dd.total_fault_idle_gap):.2f}\")\n",
    "\n",
    "# make an average ratio, with a fudge factor for time lost at ends of night\n",
    "ave_ratio = np.nanmean((dd.night_hours - dd.total_fault_idle_gap - 1.8)/dd.night_hours)\n",
    "ave_sim_ratio = np.mean((dd.night_hours - 0.37)/(dd.night_hours))\n",
    "print(f\"some kind of average ratio {ave_ratio:.2f} compare to {ave_sim_ratio:.2f}\")\n",
    "print(f\"Slew performance ratio {slew_eff / ideal_eff:.2f}\")\n",
    "print(f\"System availability estimate all: {np.nanmean(dd.ratio_all_times):.2f}\")\n",
    "print(f\"System availability estimate fbs: {np.nanmean(dd.ratio_fbs_times):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, len(dd))\n",
    "y = ((dd.night_hours - dd.total_fault_idle_gap - 1.8)/dd.night_hours) / ((dd.night_hours - 0.37)/(dd.night_hours)) * slew_eff / ideal_eff\n",
    "plt.plot(x, y, marker='.')\n",
    "_ = plt.xticks(x, dd.index, rotation=90)\n",
    "_ = plt.ylabel(\"efficiency relative to v5.1\")\n",
    "plt.figure()\n",
    "_ = plt.hist(y, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0.5, 2.8, 0.05)\n",
    "q = visits.query(\"science_program == 'BLOCK-407' and day_obs >= 20251102\")\n",
    "_ = plt.hist(q.fwhm_eff.values, bins=bins, density=False, alpha=0.4, label='407')\n",
    "q = visits.query(\"science_program == 'BLOCK-408' and day_obs >= 20251102\")\n",
    "_ = plt.hist(q.fwhm_eff.values, bins=bins, density=False, alpha=0.4, label='408')\n",
    "plt.legend()\n",
    "plt.ylabel(\"Fraction of images\")\n",
    "plt.xlabel(\"FWHM (arcseconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayobs = [20251116]\n",
    "q = visits.query(\"science_program in @programs and day_obs in @dayobs\")\n",
    "qq = q.query(\"slew_distance < 0.001\")\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(q.seq_num, q.altitude, 'r.')\n",
    "plt.plot(qq.seq_num, qq.altitude, 'o', markerfacecolor='None', markeredgecolor='b')\n",
    "plt.xlabel(\"seq_num\")\n",
    "plt.ylabel(\"Altitude (deg)\")\n",
    "plt.figure(figsize=(20,  5))\n",
    "plt.plot(q.seq_num, q.physical_rotator_angle, 'r.')\n",
    "plt.plot(qq.seq_num, qq.physical_rotator_angle, 'o', markerfacecolor='None', markeredgecolor='b')\n",
    "plt.xlabel(\"seq_num\")\n",
    "plt.ylabel(\"physical rotator angle (deg)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_baseline  = False\n",
    "if compare_baseline:\n",
    "    try:\n",
    "        opsdb = \"/Users/lynnej/opsim/fbs_5.1/baseline_v5.1.0_10yrs.db\"\n",
    "        conn = sqlite3.connect(opsdb)\n",
    "    except: \n",
    "        opsdb = get_baseline()\n",
    "        conn = sqlite3.connect(opsdb)\n",
    "    \n",
    "    b_visits = pd.read_sql(f\"select * from observations where night < 365\", conn)\n",
    "    \n",
    "    tconsdb = sci.obs_start_mjd.max() - sci.obs_start_mjd.min()\n",
    "    print(f\"comparing visits within {tconsdb} days of start\")\n",
    "    baseline_visits = b_visits.query(\"observationStartMJD - observationStartMJD.min() < @tconsdb\")\n",
    "    \n",
    "    xx = baseline_visits.groupby(\"observation_reason\").agg({'observationStartMJD': \"count\"}).rename({\"observationStartMJD\": \"baseline_v5.1.0\"}, axis=1)\n",
    "    xa = sci.groupby(\"observation_reason\").agg({'obs_start_mjd': 'count'}).rename({\"obs_start_mjd\": \"consdb\"}, axis=1)\n",
    "    print(len(sci), len(baseline_visits), 'sci/baseline', len(sci)/len(baseline_visits))\n",
    "    x = pd.concat([xa, xx], axis=1)\n",
    "    x.loc['total'] = x.sum(axis=0)\n",
    "    display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_visits = visits.query(\"bad_flag==0 and observation_reason.str.contains('DD') or observation_reason.str.contains('ddf')\").copy()\n",
    "if len(ddf_visits) > 0:\n",
    "    print(\"n visits per band\")\n",
    "    ddf_visits.loc[:, 'observation_reason'] = ddf_visits.observation_reason.str.lower()\n",
    "    ss = ddf_visits.groupby([\"observation_reason\", \"band\"]).agg({'obs_start_mjd': 'count'})\n",
    "    ss = ss.reset_index('band').pivot(columns=[\"band\"]).droplevel(0, axis=1)\n",
    "    ss['all'] = ss.sum(axis=1)\n",
    "    order = ['u', 'g', 'r', 'i', 'z', 'y', 'all']    \n",
    "    display(ss.query(\"observation_reason.str.contains('dd')\")[[o for o in order if o in ss.columns]])\n",
    "    \n",
    "    print(\"n days per band\")\n",
    "    ss = ddf_visits.groupby([\"observation_reason\", \"band\"]).agg({'day_obs': 'nunique'})\n",
    "    ss = ss.reset_index('band').pivot(columns=[\"band\"]).droplevel(0, axis=1)\n",
    "    ss['all'] = ddf_visits.groupby(\"observation_reason\").agg({'day_obs': 'nunique'})\n",
    "    display(ss.query(\"observation_reason.str.contains('dd')\")[[o for o in order if o in ss]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calc = True\n",
    "if run_calc:\n",
    "    gsci = sci.query(\"bad_flag == 0\")\n",
    "    nvisits = {}\n",
    "    coadd = {}\n",
    "    m_nvis = maf.CountMetric(col='obs_start_mjd', metric_name = \"Nvisits\")\n",
    "    m_coadd = maf.Coaddm5Metric(m5_col='cat_m5')\n",
    "    s = maf.HealpixSlicer(nside=64, lon_col='s_ra', lat_col='s_dec', rot_sky_pos_col_name = 'sky_rotation')\n",
    "    for b in ['u', 'g', 'r', 'i', 'z', 'y', 'all']:\n",
    "        constraint = f\"{b}\"\n",
    "        if b == 'all':\n",
    "            opsvis = gsci.to_records()\n",
    "        else:\n",
    "            opsvis = gsci.query(\"band == @b\").to_records()\n",
    "        nvisits[b] = maf.MetricBundle(m_nvis, s, constraint)\n",
    "        coadd[b] = maf.MetricBundle(m_coadd, s, constraint)\n",
    "        g = maf.MetricBundleGroup({f'nvisits {b}': nvisits[b], f'coadd {b}': coadd[b]}, None)\n",
    "        if len(opsvis) > 0:\n",
    "            g.run_current(constraint, opsvis)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = plot.get_background(nside=64)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(16, 10),)\n",
    "axdict = {\"u\": ax[0][0], \"g\": ax[0][1], \"r\": ax[0][2],\n",
    "          \"i\": ax[1][0], \"z\": ax[1][1], \"y\": ax[1][2], \"all\": None}\n",
    "for b in [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]:\n",
    "    if nvisits[b].metric_values is not None:\n",
    "        if len(nvisits[b].metric_values.compressed()) > 1:\n",
    "            vmax = np.percentile(nvisits[b].metric_values.compressed(), 95)\n",
    "        else:\n",
    "            vmax = None\n",
    "        label_dec = False\n",
    "        if b == 'u' or b == 'i':\n",
    "            label_dec = True\n",
    "        fig = plot.make_plot(nvisits[b], background=background, proj='McBryde', vmax=vmax, ax=axdict[b], title=f\"LSSTCam band {b}\", label_dec=label_dec)\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(out_dir, f\"lsstcam_nvisits_band.png\"), bbox_inches='tight')\n",
    "\n",
    "vmax = np.percentile(nvisits['all'].metric_values.compressed(), 95)\n",
    "fig = plot.make_plot(nvisits['all'], background=background, proj='mcbryde', vmin=None, vmax=vmax, ax=None, title=f\"LSSTCam visits\")\n",
    "fig = plot.make_plot(nvisits['all'], background=background, proj='laea', vmin=None, vmax=vmax, ax=None, title=f\"LSSTCam visits\")\n",
    "#fig.savefig(os.path.join(out_dir, f\"lsstcam_nvisits.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
